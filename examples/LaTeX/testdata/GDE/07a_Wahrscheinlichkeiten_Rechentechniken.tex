\section{Wahrscheinlichkeiten I: Rechentechniken}
\subsection{Einführung}
\subsubsection{Zielsetzung}
\label{Wahrscheinlichkeitsrechnung}

In dieser und der folgenden Woche werden die mathematischen
Grundlagen der Wahrscheinlichkeitstheorie besprochen, die für die
Theorie der Entscheidungen unter Risiko (d.h. solchen Entscheidungen, bei denen
wir im Gegensatz zu Entscheidungen unter Unwissenheit die Wahrscheinlichkeiten
für die möglichen Zustände oder Zufallsereignisse kennen) benötigt werden. 

Folgendes steht auf dem Programm:

\begin{enumerate}
  \item Herleitung der wesentlichen Gesetze der elementaren
  Wahrscheinlichkeitstheorie, also insbesondere:
  \begin{enumerate}
    \item {\em Wahrscheinlichkeit von "`und"'-verknüpften Ereignissen}: Wie
    groß ist die Wahrscheinlichkeit, dass von zwei möglichen Zufallsereignissen,
    deren jeweilige Wahrscheinlichkeit bekannt ist, beide eintreten?
    \item {\em Wahrscheinlichkeit von "`oder"'-verknüpften Ereignissen}: Wie
    groß ist die Wahrscheinlichkeit, dass von zwei möglichen Ereignissen das
    eine oder das andere eintritt?
    \item {\em Bedingte Wahrscheinlichkeit}: Wie groß ist die
    Wahrscheinlichkeit, dass ein Ereignis eintritt, dass von einem anderen
    abhängt, unter der Bedingung, dass das andere Ereignis schon eingetreten
    ist? Und im Gegensatz dazu, wie groß ist die Wahrscheinlichkeit, dass es
    überhaupt, also ohne diese Bedingung, eintritt?
  \end{enumerate}
  \item Der Satz von Bayes. Das Theorem von Bayes ist grundlegend für die
  Berechnung von bedingten Wahrscheinlichkeiten und hat zahlreiche Anwendungen
  in der Statistik, der Entscheidungstheorie und der Philosophie.
\end{enumerate}

Am Ende dieses Kapitel wird jeder Aufgaben wie die folgende mühelos lösen
können:

\begin{quotation}
 Ca. 3\% aller 70-jährigen haben Alzheimer. Auch
wenn Alzheimer bisher nicht geheilt werden kann, ist die
Früherkennung eine wichtige Voraussetzung für vorbeugende, den
Krankheitsverlauf evtl. mildernde Maßnahmen. Leider lässt sich
Alzheimer nur schwer präzise diagnostizieren. (Erst durch
Gewebeuntersuchungen am verstorbenen Patienten lässt sich mit
Sicherheit feststellen, ob eine Alzheimererkrankung vorlag.)
Angenommen einmal, die Forschung hätte einen Gedächtnistest
entwickelt, durch den eine vorliegende Alzheimererkrankung
mit 95\%-iger Sicherheit diagnostizierbar ist, an dem im
Durchschnitt aber auch 2\% der älteren Menschen scheitern, selbst wenn sie
nicht an Alzheimer erkrankt sind.

Angenommen, Sie sind Ärztin oder Arzt und untersuchen einen
70-jährigen Patienten mit Hilfe des Gedächnistests. Es zeigt sich, dass
der Patient nicht mehr in der Lage ist, die Aufgaben des Tests zu lösen. Wie
groß ist die Wahrscheinlichkeit, dass der Patient an Alzheimer erkrant ist?
\end{quotation}

Um es vorweg zu nehmen: Die Antwort "`95\%"' ist falsch! Aber warum? Dafür
eben benötigt man die Wahrscheinlichkeitsrechnung.

\subsubsection{Was sind Wahrscheinlichkeiten?}
Bevor aber auf das mathematische Kalkül der Wahrscheinlichkeitsrechnung
eingegangen wird, ist zunächst etwas zu der Frage zu sagen, was
\marginline{Empirische Typen von Wahrscheinlichkeiten}
Wahrscheinlichkeiten eigentlich sind. Es gibt drei Arten von Phänomenen, auf die
man das Wahrscheinlichkeitskalkül anwenden kann:

\begin{enumerate}
  \item {\em Häufigkeiten} bei einer größeren Menge oder Folge von Ereignissen.
  So besagt die Aussage, dass ein 70-jähriger mit 3\%-iger Wahrscheinlichkeit an
  Alzheimer leidet, nichts weiter, als dass eben unter den 70-jährigen die
  Alzheimerkrankheit mit einer Häufigkeit von 3\% auftritt. (Jeder einzelne
  70-jährige dagegen hat die Alzheimerkrankheit oder auch nicht. Aber kein
  70-jähriger hat 3\% Alzheimer.) Die Wahrscheinlichkeitsaussage bezieht sich
  in diesem Fall also nur auf die Häufigkeit eines Zustands in einer
  Gesamtheit.
  \item {\em Glaubensgrade} oder auch "`subjektive Wahrscheinlichkeiten"': Wenn
  eine Ärztin einen Patienten dem oben beschriebenen Gedächsnistest unterzogen hat, 
  und nun (mit Hilfe des
  Bayes'schen Lehrsatzes) die korrekte Wahrscheinlichkeit berechnet hat, mit der
  der Patient an Alzheimer erkrankt ist, dann wird sie oder er genau in dem Grad
  davon überzeugt sein, dass der Patient an Alzheimer leidet, der dieser
  Wahrscheinlichkeit entspricht. Wiederum gilt: Der Patient hat entweder Alzheimer oder kein
  Alzheimer. Die Wahrscheinlichkeit sagt bei genauer Auslegung nur etwas
  darüber aus, bis zu welchem Grad man davon ausgehen muss, dass eine
  Alzheimererkrankung vorliegt. 
  \item {\em Objektive Wahrscheinlichkeiten} (Propensitäten): Die
  Wahrscheinlichkeit kann aber auch die inhärente Eigenschaft eines einzelnen 
  Vorgangs beschreiben. So hat
  die Wahrscheinlichkeit, beim Würfeln eine Sechs zu würfeln, offensichtlich
  etwas mit dem symmetrischen Aufbau des Würfels zu tun. Man kann die
  Wahrscheinlichkeit, eine Sechs zu würfeln, daher als eine objektive
  Eigenschaft des Vorgangs eines Würfelwurfs betrachten.\footnote{Dagegen
  könnte eingewandt werden, dass beim Würfeln als einem nach der klassischen
  Mechanik streng deterministisch zu beschreibenden Vorgang das Ergebnis
  schon vorherbestimmt ist, so dass man nicht im wörtlichen Sinne von einer
  "`objektiven Wahrscheinlichkeit"' seines Eintretens sprechen könne. Da
  es aber andererseits noch nie jemanden gelungen ist, Würfelwürfe tatsächlich 
 vorherzusagen, so spricht -- ungeachtet der Beschreibung des Systems durch
 eine deterministische Theorie -- nichts dagegen, den Ausgang des Würfelwurfs
 als objektiv zufällig zu betrachten. Mit dieser Interpretation folge ich der
 (allerdings etwas umstrittenen) Theorie von Nancy Cartwright, der zufolge
 (natur-)wissenschaftliche Theorien nur bei den Vorgängen überhaupt gültig
 sind, an denen man sie auch nachweisen kann \cite[]{cartwright:1999}. }
\end{enumerate}

Die Tatsache, dass man auf alle drei Klassen von Phänomenen ein- und dasselbe
wahrscheinlichkeitstheoretische Kalkül anwendet -- zudem es übrigens, sofern man
seine Anwendung auf den entsprechenden empirischen Phänomenbereich überhaupt
zugesteht, keine Alternative gibt -- darf nicht darüber hinwegtäuschen, dass es
sich -- empirisch betrachtet -- um sehr unterschiedliche Phänomene handelt. Das
gilt trotz der Tatsache, dass die Interpretation, um
welche Art von (empirischer) Wahrscheinlichkeit es sich handelt, nicht
in jedem Fall eindeutig oder zwingend ist. So kann man die Wahrscheinlichkeit,
beim Würfeln eine Sechs zu würfeln statt als Propensität des Systems
"`Würfel"' auch als Häufigkeit verstehen, mit der bei einer großen Anzahl von
Würfen die Sechs auftritt.


\subsection{Grundlegende Gesetze der Wahrscheinlichkeitsrechnung}

Wenn wir in der Entscheidungstheorie von Wahrscheinlichkeiten
sprechen, dann sind fast immer die Wahrscheinlichkeiten von Zuständen oder von
Zufallsereignissen gemeint. Für die Wahrscheinlichkeit eines Ereignisses $E$
schreibt man:
\begin{displaymath}
P(E) = a \qquad 0 \leq a \leq 1
\end{displaymath}
Lies: Die Wahrscheinlichkeit, dass das Ereignis $E$ eintritt beträgt $a$. Statt
über die Wahrscheinlichkeit von Ereignissen zu reden, können wir ebensogut über die
Wahrscheinlichkeit der Wahrheit von Aussagen reden, die besagen, dass
ein Ereignis eintritt. Wenn $q$ die Aussage ist, dass das Ereignis $E$
eintritt, dann ist mit \marginline{Definition der Wahrscheinlichkeit}
\begin{displaymath}
P(q) = a \qquad 0 \leq a \leq 1
\end{displaymath}
die Wahrscheinlichkeit beschrieben, dass die Aussage $q$ wahr ist. Da $q$
aussagt, dass E eintritt, ist diese Wahrscheinlichkeit natürlich genau dieselbe wie
diejenige, dass E eintritt. Spricht man von den Wahrscheinlichkeiten
von Aussagen über Ereignisse, so erlaubt dies ohne weitere Umstände
die aussagenlogischen und modallogischen\footnote{Während die Aussagenlogik nur
die Wahrheit und Falschheit von Aussagen einbezieht, behandelt die Modallogik
auch solche Eigenschaften wie die {\em Möglichkeit} und {\em Notwendigkeit} von
Aussagen. So ergibt sich in der Modallogik z.B. dass die Negation einer
Aussage, die {\em unmöglich} wahr sein kann, {\em notwendig} wahr ist.}
Verknüpfungen von Aussagen anzuwenden und die Wahrscheinlichkeiten von aussagenlogisch 
verknüpften Aussagen zu bestimmen. Aber im Grunde handelt es sich dabei nur 
um eine andere Redeweise. Besonders in der mathematischen Literatur zur 
Wahrscheinlichkeitstheorie ist es darüber hinaus auch üblich den 
Wahrscheinlichkeitsbegriff in Bezug auf Ereignismengen zu definieren, 
die die Teilmengen eines Ereignisraums sind, wobei man zusammengesetzte 
Ereignisse noch einmal von Elementarereignissen 
unterscheidet \cite[S. 1ff.]{bosch:1976}. Der
Einfachheit halber beschränken wir uns, Resnik folgend \cite[S.
45ff.]{resnik:1987}, hier meist aber auf die Wahrscheinlichkeiten von
Ereignissen bzw. Aussagen über Ereignisse.

Die Wahrscheinlichkeitsrechnung wurde 1993 von dem russischen Mathematiker
Andrej Nikolajewitsch Kolmogorow axiomatisiert. Seitdem beruht die gesamte
\marginline{Kolmogorow-Axiome}
Wahrscheinlichkeitsrechnung auf folgenden drei (harmlos wirkenden) Axiomen:

\begin{description}
\item[Axiom 1:] Für die Wahrscheinlichkeit $P(p)$ eines Ereignisses $p$ gilt:
\[0 \leq P(p) \qquad P(p) \in \mathbb{R}\]
\item[Axiom 2:] Wenn $p$ sicher ist, dann gilt:
\[P(p) = 1\]
\item[Axiom 3:] Wenn die Ereignisse $p$ und $q$ sich ausschließen, dann gilt:
\[P(p \vee q) = P(p) + P(q)\]
\end{description}

Sofern die Menge möglicher Ereignisse abzählbar unendlich viele Ereignisse
enthält, ersetzt man Axiom 3 durch:

\begin{description}
\item[Axiom 3':] Seien $p_1, p_2, \ldots$ höchstens abzählbar
unendlich viele Ereignisse und paarweise unvereinbar, dann gilt:
\[P(\bigvee p_i) = P(p_1 \vee p_2 \vee \ldots) = P(p_1) + P(p_2) + 
\ldots = \sum P(p_i)\]   
\end{description} 

Es ist bemerkenswert, dass man mit diesen drei Axiomen auskommt, und dass sich
alle anderen Gesetze für das Rechnen mit Wahrscheinlichkeiten daraus ableiten
lassen. Insbesondere kann man aus diesen Axiomen relativ unmittelbar folgende
\marginline{Elementare Gesetze}
{\em Corrolarien} ableiten:

\begin{enumerate}
  \item $P(\neg p) = 1 - P(p) \qquad$ ({\em inverse Wahrscheinlichkeit})

  {\small Beweis: Da $p \vee \neg p$ sicher ist, gilt nach Axiom 2: 
  $P(p \vee \neg p) = 1$. Da $p$ und $\neg p$ sich ausschließen, kann man Axiom
  3 anwenden: \[P(p) + P(\neg p) = P(p \vee \neg p) = 1\] Daraus folgt
  unmittelbar: $P(\neg p) = 1 - P(p) \qquad$}
  
  \item Wenn $q$ unmöglich, dann $P(q) = 0 \qquad$ ({\em
  Null-Wahrscheinlichkeit})

  {\small Beweis: Wenn $q$ unmöglich ist, dann ist $\neg q$ sicher. Damit
  ergibt sich aus dem vorhergehenden und Axiom 2: 
  \[P(q) = 1 - P(\neg q) = 1 - 1 = 0\]}
  
  \item Wenn p aus q folgt, dann $P(q) \leq P(p) \qquad$ ({\em Monotonie})
  
  {\small Beweis: Wenn $p \leftarrow q$, dann gilt $p \Leftrightarrow q \vee (\neg q \wedge
  p)$. Da aber auch gilt, dass $q$ und $(\neg q \wedge p)$ sich ausschließen,
  ist die Voraussetzung von Axiom 3 erfüllt und wir können folgern, dass:
  \[P(p) = P(q) + P(\neg q \wedge p)\] Da wegen Axiom 1 sowohl $P(q) \geq 0$
  als auch $P(\neg q \wedge p) \geq 0$, können wir daraus folgern, dass $P(q)
  \leq P(p)$. (Da es nicht strikt ausgeschlossen ist, dass $\neg q \wedge p$
  wahr ist, kann es in der Tat auch Fälle geben in denen $<$ also {\em echt
  kleiner} gilt.)}

  \item $P(p) \leq 1$ \qquad ({\em obere Grenze der Wahrscheinlichkeit})
  
  {\small Beweis: Logisch betrachtet folgt ein sicheres Ereignis q aus jedem
  Ereignis p. (Da q als sicheres Ereignis immer gilt, gilt es insbesondere auch
  wenn p gilt.) Für jedes Ereignis p gilt also $P(p) \leq P(q)$, wenn q sicher
  ist. Da nach dem 2. Axiom $P(q) = 1$, folgt die Behauptung.}

  \item $P(q \vee p) = P(q) + P(p) - P(q \wedge p) \qquad$ ({\em
  oder-verknüpfte Ereignisse})
  
  {\small Beweis: Da $q \vee p$ äquivalent ist mit $q \vee (\neg q \wedge p)$
  und $q$ und $\neg q \wedge p$ sich ausschließen, gilt nach Axiom 3: 
  \[P(q \vee p) = P(q \vee (\neg q \wedge p)) = P(q) + P(\neg q \wedge p)\]
  Da aber weiterhin $p \Leftrightarrow (q \wedge p) \vee (\neg q \wedge p)$ und auch $q
  \wedge p$ und $\neg q \wedge p$ sich ausschließen, gilt wiederum nach Axiom 3:
  \[P(p) = P((q \wedge p) \vee (\neg q \wedge p)) = P(q \wedge p) + P(\neg q
  \wedge p)\]
  Dies lässt sich umformen zu:
  \[P(\neg q \wedge p) = P(p) - P(q \wedge p)\]
  Indem wir den Term $P(\neg q \wedge p)$ in der ersten Gleichung durch diesen
  Ausdruck ersetzen erhalten wir die Behauptung.}
\end{enumerate}

Der "`Sinn"' der meisten dieser Corrolarien drüfte relativ einleuchtend sein.
Etwas verblüffend könnte höchstens die Monotoniebedingung (3.) erscheinen. Wenn
p aus q folgt ($q \rightarrow p$), warum gilt dann, dass die Wahrscheinlichkeit
von q kleiner ist als die von p ($P(q) \leq P(p)$) und nicht umgekehrt? Man
kann sich das folgendermaßen klar machen: q ist eine {\em hinreichende}, aber
keine notwendige Voraussetzung von p. Immer wenn q gegeben ist, ist damit auch
p gegeben. Aber umgekehrt kann p auch gegeben sein, ohne dass q gegeben ist. So
gesehen ist p wahrscheinlicher als q.

Alle oben aufgeführten Gesetzmäßigkeiten betreffen unbedingte
Wahrscheinlichkeiten. Als nächstes ist der Begriff der bedingen
Wahrscheinlichkeit einzuführen. Mit 
\[ P(p|q) \]
bezeichnen wir die Wahrscheinlichkeit eines Ereignisses p unter der Bedingungen,
dass das Ereignis q eingetreten ist.

Mathematisch kann die bedingte Wahrscheinlichkeit $P(p|q)$ durch folgende
\marginline{Bedingte Wahrscheinlichkeit}
Definition eingeführt werden\label{bedingteWahrscheinlichkeit}: \[ P(p|q) :=
\frac{P(p \wedge q)}{P(q)} \qquad P(q) > 0 \] In Umgangssprache übertragen
bedeutet dies, dass die bedingte Wahrscheinlichkeit als die Wahrscheinlichkeit
definiert ist, mit der beide Ereignisse (das Bedingte und das Bedingende)
eintreten, geteilt durch die Wahrscheinlichkeit, dass die Bedingung eintritt. Für
den Fall, dass $P(q)=0$, setzt man üblicherweise $P(p|q) := 0$. Diese
Festsetzung ist möglich und sinnvoll, weil damit immer noch das unten angegebene
Multiplikationsgesetz erfüllt ist.

Wenn es sich dabei um die "`Definition"' bedingter Wahrscheinlichkeit handelt,
dann könnte man die Frage aufwerfen, warum man die bedingte Wahrscheinlichkeit
gerade so definieren soll und ob man sie nicht auch anders definieren könnte.
Betrachtet man die Wahrscheinlichkeitsrechnung nicht allein als eine rein
mathematische Disziplin, in welchem Falle die Definition in der Tat willkürlich
wäre, solange sie nicht den voher (ebenso willkürlich) festgelegten Axiomen
widerspricht, dann muss der Rechtfertigungsgrund für diese Definition genauso wie
für die vorhergehenden Kolmogorowschen Axiome in letzter Instanz ein empirischer
sein: Die Axiome und Definitionen der Wahrscheinlichkeitsrechnung sind gültig,
insofern sich damit Gesetzmäßigkeiten empirischer Wahrscheinlichkeitsphänomene
richtig erfassen lassen. Andernfalls wären sie nicht mathematisch falsch aber
empirisch unanwendbar. (Dasselbe gilt übrigens für alle Bereiche der Mathematik,
sogar für das Rechnen mit natürlichen Zahlen. Empirisch betrachtet, ist $2+2=4$,
weil zwei Äpfel und noch zwei Äpfel vier Äpfel sind und weil zwei Häuser und noch
zwei Häuser vier Häuser sind, usf. Gäbe es irgendeinen Planeten auf dem zwei
Äpfel und noch zwei Äpfel fünf statt vier Äpfel sind, dann wäre damit nicht die
Mathematik natürlicher Zahlen widerlegt, aber sie wäre auf diesem Planeten
unanwendbar. Wem das Beispiel zu abwegig vorkommt, der mag sich überlegen, dass
die einfache Additivität schon bei Volumengrößen nicht gegeben ist. Wenn man 1
Liter Alkohol und 1 Liter Wasser mischt, dann bekommt man nicht etwa $1+1=2$
Liter Alkohol-Wasser-Gemisch, sondern etwas weniger als 2 Liter! Ob und worauf
sich die Gesetze der Addition, Subtraktion, Multiplikation etc. anwenden lassen
ist also eine rein empirische Frage. A priori lässt sich nur beweisen, dass
$1+1=2$,\footnote{Dergleichen lässt sich tatsächlich beweisen. Näheres dazu
auf: \url{http://us.metamath.org/mpegif/mmset.html\#trivia}. Ich bin Matthias
Brinkmann für den Hinweis auf diese Webseite dankbar!} aber nicht dass eine Mengeneinheit von
irgendetwas (z.B. Flüssigkeit) plus noch eine Mengeneinheit von irgendetwas zwei
Mengeneinheiten von irgendetwas sind.)

Um nun aber die oben aufgeführte Definition der bedingten Wahrscheinlichkeit noch
etwas besser zu motivieren, kann man darauf hinweisen, dass sich aus ihr
unmittelbar das uns schon zuvor bekannte (oder wie man riskanterweise auch
manchmal behauptet: das uns intuitiv einleuchtende) Gesetz für die {\em
Multiplikation der Wahrscheinlichkeiten} von und-verknüpften Ereignissen ergibt:
\marginline{Multi\-pli\-ka\-tions\-gesetz}
\[ P(p \wedge q) = P(p)\cdot P(q|p) \] Wegen der Kommutativität des logischen
und-Operators "`$\wedge$"' ergibt sich daraus unmittelbar auch: \[ P(p \wedge q) =
P(q \wedge p) = P(q)\cdot P(p|q) \] Beim Gesetz der Multiplikation von
Wahrscheinlichkeiten ist zu beachten, dass die Wahrscheinlichkeit des einen
Ereignisses die unbedingte Wahrscheinlichkeit ist, die des anderen Ereignisses
aber stets die Wahrscheinlichkeit unter der Bedingung, dass das eine Ereignis
eingetreten ist.

Dieser Zusammenhang wird bei empirischen Beispielen manchmal verdeckt.
Berechnet man beispielsweise die Wahrscheinlichkeit, dass man bei zwei
Münzwürfen beidemale hintereinander Zahl erhält, so würde man 1/2 mal 1/2
rechnen, also scheinbar $P(p)\cdot P(q)$ rechnen, wenn mit p die Aussage
"`Beim ersten Wurf lag die Zahl oben"' und mit q die Aussage "`Beim zweiten
Wurf lag die Zahl oben"' gemeint ist. Aber auch hier muss man Korrekterweise
$P(p)\cdot P(q|p)$ rechnen, nur sind beim Münzwurf die Ereignisse p und q
unabhängig, so dass -- wiederum per Definition für unabhängige Ereignisse
(siehe unten) -- gilt $P(q|p) = P(q)$, womit die Rechnung 
$P(p)\cdot P(q|p)$, wenn man Zahlen einsetzt, eben genauso aussieht 
wie die Rechnung $P(p)\cdot P(q)$. In Wirklichkeit ist es aber eine andere
Rechnung.

Deutlicher wird dies an einem zweiten Beispiel: \label{AktienBeispiel} Zu
berechnen sei die Wahrscheinlichkeit, dass ein Unternehmen U eine Gewinnwarnung
ausgibt {\em und} der Aktienkurs von U dennoch steigt. Wenn $q$ die Aussage ist
"`U gibt eine Gewinnwarnung aus"' und p die Aussage "`Der Aktienkurs von U steigt"'
und $p|q$ die Aussage "`Der Aktienkurs von U steigt, nachdem eine Gewinnwarnung
ausgegeben wurde"', dann ist recht offensichtlich, dass man, um die
Wahrscheinlichkeit zu bestimmen, dass eine Gewinnwarnung ausgegeben wird {\em
und} der Aktienkurs steigt, rechnen muss $P(p \wedge q) = P(q)\cdot P(p|q)$.
Denn wenn schon einmal eine Gewinnwarnung ausgegeben wurde, dann ist die
Wahrscheinlichkeit, dass der Aktienkurs trotzdem steigt, natürlich eine ganz
andere als die, dass der Aktienkurs einfach so steigt.

Aus dem Gesetz der Multiplikation von Wahrscheinlichkeiten und-ver\-knüpf\-ter
Ereignisse ergibt sich eine naheliegende Definition für die Unabhängigkeit von
Ereignissen. Zwei Ereignisse p und q sind {\em statistisch unabhängig}, 
\marginline{Statistische Unabhängigkeit} wenn: \[
P(p \wedge q) = P(p)\cdot P(q) \] Da das Gesetz der Multiplikation von
Wahrscheinlichkeiten bereits besagt, dass $P(p \wedge q) = P(p)\cdot P(q|p) =
P(q)\cdot P(p|q)$, so folgt für unabhängige Ereignisse unmittelbar: \[ P(p|q) =
P(p) \qquad \mbox{und} \qquad P(q|p) = P(q) \] In Worte gefasst sind zwei
Ereignisse also dann statistisch unabhängig voneinander, wenn sie als Bedingung
des anderen keinen Einfluss auf die Größe von dessen Wahrscheinlichkeit ausüben.
Wenn man mit $p|q$ das Ereignis $p$ unter der Bedingung von $q$ darstellt, so
ist damit noch nicht ausgeschlossen, dass das Ereignis p unabhängig von der
Bedingung $q$ ist. (Umgangssprachlich würden wir freilich nur von den
Bedingungen eines Ereignisses sprechen, wenn das Ereignis gerade nicht unabhängig davon ist.
Andernfalls würden wir den Ausdruck "`Bedingung"' wahrscheinlich nicht verwenden.
Die Fachsprache deckt sich hier, wie so oft, nicht mit der Umgangssprache!)

Sind $p$ und $q$ statistisch unabhängig von einander, dann gilt auch, dass $p$
und $\neg q$ statistisch unabhängig sind. 

{\em Beweis}: 
\[ p \Leftrightarrow (p \wedge q) \vee (p \wedge \neg q) \] 
Da $(p \wedge q)$ und $(p \wedge \neg q)$ einander ausschließen, gilt nach Axiom
3:
\[ P(p) = P((p \wedge q) \vee (p \wedge \neg q)) =
   P(p \wedge q) + P(p \wedge \neg q) \]
Das lässt sich umformen zu:
\[ P(p \wedge \neg q) = P(p) - P(p \wedge q) \]
Da nach Voraussetzung $p$ und $q$ statistisch unabhängig sind, gilt: 
$P(p \wedge q) = P(p)\cdot P(q)$. In der vorhergehenden Gleichung dürfen wir
also $P(p \wedge q)$ durch $P(p)P(q)$ ersetzen und erhalten:
\[ P(p \wedge \neg q) = P(p) - P(p)P(q) = P(p)\cdot (1 - P(q)) \]
Nach Corrolar 1 ist aber $1 - P(q) = P(\neg q)$. Somit erhalten wir:
\[ P(p \wedge \neg q) = P(p)P(\neg q) \]
Also sind nach der Definition der statistischen Unabhängigkeit auch
$p$ und $\neg q$ voneinander unabhängig. {\em q.e.d.}

Dementsprechend gilt: Wenn $p$ statistisch unabhängig von $q$ ist, dann ist
nicht nur $P(p|q) = P(p)$ sondern auch $P(p|\neg q) = P(p)$. Kurz, wenn $p$
unabhängig von $q$ ist, dann ändert sich die Wahrscheinlichkeit von $p$ nicht
durch irgendwelche Informationen hinsichtlich der Frage, ob $q$ eingetreten ist
oder nicht. (Aber genauso würden wir es von unabhängigen Ereignissen ja auch
erwarten, oder?) 

Bei mehr als zwei Ereignissen legt man wie bei der Unvereinbarkeit üblicherweise
die {\em paarweise} Unabhängigkeit zu Grunde. Ähnlich wie bei paarweise {\em
unvereinbaren} Ereignissen die Wahrscheinlichkeit, dass mindestens eins davon
eintritt (oder-Verknüpfung!), der {\em Summe} der Wahrscheinlichkeiten der
einzelnen Ereignisse entspricht, so ist die Wahrscheinlichkeit, dass alle
Ereignisse einer Menge von paarweise {\em unabhängigen} Ereignissen eintreten,
gleich dem {\em Produkt} der Wahrscheinlichkeiten der Einzelereignisse.

Der Umgang mit bedingten Wahrscheinlichkeiten ist nicht immer vollkommen
intuitiv.\marginline{Nicht-Monotonie bedingter W'keiten} Einige Dinge sollte man
im Auge behalten: Durch das Hinzufügen von Bedingungen kann die
Wahrscheinlichkeit eines Ereignisses größer oder auch kleiner werden oder auch
gleich bleiben. (Es ist also nicht wahr, dass irgendein Grundsatz der Art: "`Je
mehr Bedingungen, desto unwahrscheinlicher ein Ereignis"' gelten würde.)
Beispiel: Angenommen, auf Grund historischer Erfahrungswerte weiß man, dass die
Wahrscheinlichkeit, dass die Aktienkurse eines großen Gartenbauunternehmens im
Frühjahr mit einer bestimmten Wahrscheinlichkeit $w$ steigen. Dann wird die
Wahrscheinlichkeit, dass sie steigen, wenn das Gartenbauunternehmen im ersten
Quartal Gewinne ausweisen konnte, sicher größer sein als $w$, während sie unter
der Bedingung, dass es Verluste melden musste, wahrscheinlich kleiner sein wird.

Schließlich ist noch auf eine Verwechselungsmöglichkeit aufmerksam zu machen. Die
Wahrscheinlichkeit,\marginline{Unterschied von bedingter W'keit und Implikation}
dass "`$q$ unter der Bedingung, dass $p$"' eintritt (also $P(q|p)$) ist nicht zu
verwechseln mit der Wahrscheinlichkeit von "`$q$ wenn $p$"' ($P(p \rightarrow
q)$). Ein Beispiel: Die Wahrscheinlichkeit aus einem Stapel von Karten eine Karte
mit Herz zu ziehen ($q$) beträgt $1/4$. Wenn man aber vorher alle schwarzen
Karten aus dem Stapel entfernt, dann ist die Bedingung gegeben ist, dass die
gezogene Karte eine rote Karte ist ($p$), und die Wahrscheinlichkeit, dass die
Karte unter dieser Bedingung Herz ist, beträgt $P(q|p) = 1/2$. Andererseits aber
beträgt die Wahrscheinlichkeit, dass es wahr ist, dass "`wenn eine rote Karte gezogen
wird, dann ist es eine Herz-Karte"' $P(p \rightarrow q) = 3/4$, denn die Aussage
ist auch dann wahr, wenn überhaupt keine rote Karte gezogen wird, was bereits in
der Hälfte aller Fälle gilt. Die Bedingungsaussage $q|p$ ist also nicht zu
verwechseln mit der Implikationsaussage $p \rightarrow q$. Der Unterschied ist
der zwischen der bedingten Behauptung des Folgeglieds einer Implikation und der
Behauptung der Gültigkeit einer Implikationsbeziehung selbst, ein subtiler aber
wichtiger Unterschied!


\subsection{Der Bayes'sche Lehrsatz}

Aus dem Gesetz für die Multiplikation von Wahrscheinlichkeiten 
\[ P(p \wedge q) = P(p)\cdot P(q|p) = P(q)\cdot P(p|q) \]
lässt sich durch Division von $P(p)$ bzw. $P(q)$ die {\em Bayes'sche Regel}
ableiten:\label{BayesRegel}\marginline{Bayes'sche Regel}
\[ P(p|q) = \frac{P(q|p)\cdot P(p)}{P(q)} \qquad \mbox{wenn} \qquad P(q) > 0\]

Um den eigentlichen Bayes'schen Lehrsatz abzuleiten, ist es notwendig, den
Ausdruck $P(q)$ im Nenner durch einen Ausdruck zu ersetzen, der die absolute
Wahrscheinlichkeit von $q$ nicht mehr enthält.\footnote{Man kann an dieser Stelle
durchaus die Frage stellen, warum man das tun sollte, wenn doch dadurch, wie
gleich zu sehen ist, die Formel nur sehr viel komplizierter ist. Aber wie das
eingangs zu dieser Vorlesung angeführte Beispiel vielleicht verdeutlicht hat --
wir werden gleich darauf zurück kommen -- gibt es viele Situationen, in denen wir
die unbedingten Wahrscheinlichkeiten irgendeines Vorgangs nicht kennen, wohl aber
die bedingten Wahrscheinlichkeiten.} Dazu erinnern wir uns der aus der Logik
(bzw. der Mengentheorie) bekannten Zerlegung von $q = (q \wedge p) \vee (q \wedge
\neg p)$. Da $q \wedge p$ und $q \wedge \neg p$ einander ausschließen gilt: \[
P(q) = P(q \wedge p) + P(q \wedge \neg p) \] Mit Hilfe des
Multiplikationsgesetzes ergibt sich daraus: \[ P(q) = P(q|p)\cdot P(p) + P(q|\neg
p)\cdot P(\neg p) \] Durch Einsetzen in die oben angegebene Regel ergibt sich
damit der berühmte {\em Bays'sche
Lehrsatz}:\label{BayesTheorem}\marginline{Bayes'sches Theorem} \[ P(p|q) =
\frac{P(q|p)\cdot P(p)}{P(q|p)P(p) + P(q|\neg p)P(\neg p)} \]

Wie kann man sich diese Formel am besten merken und wozu ist sie
überhaupt gut? Merken kann man sich die Formel recht leicht, wenn man
sich klar macht, dass sie die folgende Struktur hat:
\[P(p|q) = \frac{a}{a + b}\]
wobei
\[ a := P(q|p)P(p) \]
und
\[ b := P(q|\neg p)P(\neg p) \]
d.h., salopp ausgedrückt, $b$ dasselbe ist wie $a$ nur mit $\neg p$ statt $p$.
Man kann sich die Bedeutung dieser Formel mit Hilfe folgender, in
vielen Zusammenhängen nützlichen Interpretation merken: Was uns die Formel auf
der linken Seite als Ergebnis liefert ist die Wahrscheinlichkeit für die
Gültigkeit einer Annahme $p$ unter der Bedingung, dass irgendeine Probe bzw. ein
Test $q$ erfolgreich durchgeführt worden ist. Auf der rechten Seite kommen nur
drei verschiedene Terme vor. Einige davon allerdings mehrfach, nämlich:
\begin{enumerate}
  \item Die {\em Basisrate} $P(p)$, d.i. die Wahrscheinlichkeit, unter der die
  Annahme p normalerweise stimmt, sowie die inverse Basisrate $P(\neg p) = 1 -
  P(p)$
  \item Die {\em positiv-positiv Rate} $P(q|p)$, d.i. die Wahrscheinlichkeit,
  dass die Probe $q$ positiv ausfällt, wenn $p$ gegeben ist.
  \item Die {\em positiv-negativ Rate} $P(q|\neg p)$, d.i. die
  Wahrscheinlichkeit, dass die Probe $q$ positiv aus fällt obwohl $p$ nicht
  gegeben ist.
\end{enumerate}
Die letzten beiden Wahrscheinlichkeiten beschreiben Fehlerwahrscheinlichkeiten
des Testverfahrens q, und zwar für unterschiedliche Arten von Fehlern!
Die {\em negativ-positiv} und {\em negativ-negativ} Raten sind dagegen die
Inversen der entsprechenden positiv-* Raten und berechenen damit nach: $P(\neg
q|p) = 1 - P(q|p)$ bzw. $P(\neg q|\neg p) = 1-P(q|\neg p)$. Mit der Bayes'schen
Formel berechnet man also die Wahrscheinlichkeit, dass $p$ zutrifft, 
wenn ein Testverfahren $q$ positiv ausfällt. Die Bayes'sche Formel
erlaubt uns zu berücksichtigen, dass Testverfahren meistens nicht
100\%-ig perfekt sind. Die Unvollkommenheiten des Testverfahrens werden dabei
durch die positiv-positiv und die positiv-negativ Raten charakterisiert. 
Die Wahrscheinlichkeit von $p$, wenn
der Test positiv ausgefallen ist, berechnet sich, wenn man die Formel in Worte
fasst nach:\marginline{Bayes in Worten} Basisrate mal positiv-positiv Rate {\em
geteilt durch} Basisrate mal positiv-positiv Rate plus inverse Basisrate mal 
positiv-negativ Rate.

\subsubsection{Ein "`Anwendungsbeispiel"': Bayes in der medizinischen Diagnostik}

Mit diesem Wissen können wir nun auch die Aufgabe zu Beginn der Vorlesung lösen:
\begin{quotation}
 Ca. 3\% aller 70-jährigen haben Alzheimer. Auch
wenn Alzheimer bisher nicht geheilt werden kann, ist die
Früherkennung eine wichtige Voraussetzung für vorbeugende, den
Krankheitsverlauf evtl. mildernde Maßnahmen. Leider lässt sich
Alzheimer nur schwer präzise diagnostizieren. (Erst durch
Gewebeuntersuchungen am verstorbenen Patienten lässt sich mit
Sicherheit feststellen, ob eine Alzheimererkrankung vorlag.)
Angenommen einmal, die Forschung hätte einen Gedächtnistest
entwickelt, durch den eine vorliegende Alzheimererkrankung
mit 95\%-iger Sicherheit diagnostizierbar ist, an dem im
Durchschnitt aber auch 2\% der älteren Menschen scheitern, selbst wenn sie
nicht an Alzheimer erkrankt sind.\footnote{Die Zahlen sind für den Zweck der
Übungsaufgabe willkürlich gewählt und auch die Testverfahren stellen nur
natürlich nur ein erfundenes Beispiel dar. Für realistische Zahlen aus der
aktuellen Forschung, siehe
\url{http://brain.oxfordjournals.org/cgi/reprint/131/3/681}
\cite[]{kloeppel:2008}. Ich bin Matthias Brinkmann für den Hinweis auf diesen 
Artikel sehr dankbar!}
  

Angenommen, Sie sind Ärztin oder Arzt und untersuchen einen
70-jährigen Patienten mit Hilfe des Gedächnistests. Es zeigt sich, dass
der Patient nicht mehr in der Lage ist, die Aufgaben des Tests zu lösen. Wie
groß ist die Wahrscheinlichkeit, dass der Patient an Alzheimer erkrankt ist?
\end{quotation}
Bei diesem Beispiel, gilt offenbar: 

\begin{enumerate}
  \item Basisrate $P(p) = 3\%$ (Anteil der Alzheimerkranken unter den
  70-jährigen)
  \item positiv-positiv Rate $P(q|p) = 95\%$ (eine vorliegende
  Alzheimererkrankung ist mit Hilfe des Tests mit 95\%-iger Sicherheit diagnostizierbar)
  \item positiv-negativ Rate $P(q|\neg p)= 2\%$ (in 2\% der Fälle löst der Test
  "`Fehlalarm"' aus)
\end{enumerate}
 
 In die Bayes'sche Formel eingesetzt ergibt dies: 
 \[ \frac{0,03\cdot 0,95}{0,03\cdot 0,95 + 0,97\cdot 0,02} = 0,59 \]
 Mit 59\%-iger Wahrscheinlichkeit ist der Patient also an Alzheimer erkrankt.
 \marginline{Einfluss der Basisrate}
 Wie kann das sein, mag man sich fragen, dass der Wert nur 59\% beträgt, wenn
 ein Test, der die Krankheit doch zu 95\% diagnostiziert, positiv ausgefallen
 ist. Der Grund ist, dass die Krankheit
 unter den 70-jährigen überhaupt nur selten vorkommt und dass 
 damit die {\em Basisrate} recht niedrig ist.
 
 Wie nützlich der Bayes'sche Lehrsatz ist, tritt so recht dann zu Tage, wenn
 man ihn mehrfach hintereinander anwendet. Stellen Sie sich unsere Geschichte
 folgendermaßen fortgesetzt vor:
  \begin{quotation}
 Als Arzt oder Ärztin sind Sie nicht damit zufrieden, dass Sie die
 Alzheimererkrankung des Patienten bisher nur mit 59\%-iger Wahrscheinlichkeit
 diagnostizieren konnten. Also wenden Sie noch einen zweiten Test -- diesmal
 einen Test mit Rechenaufgaben an -- um ihre Diagnose ggf. zu erhärten. Der
 zweite Test ist etwas weniger zuverlässig als der erste, indem eine
 vorliegende Krankheit nur in 90\% aller Fäller richtig erkannt wird, aber auch
 in 10\% der Fälle Fehlalarm gegeben wird, obwohl gar keine Erkrankung vorliegt.
 
 Angenommen, Ihr Patient scheitert ebenfalls an den Rechenaufgaben dieses
 zweiten Tests. Mit welcher Wahrscheinlichkeit müssen Sie nun davon ausgehen, 
 dass er tatsächlich an Alzheimer erkrankt ist?
 \end{quotation}
Um die Aufgabe zu lösen, wendet man wiederum den Bayes'schen Lehrsatz an, nur
dass man diesmal als Basisrate dass Ergebnis des ersten Tests einsetzt. Wir
wissen ja schon mit 59\%-iger Wahrscheinlichkeit, dass der Patient
erkrankt ist. Die Rechnung liefert dann ein Ergebnis von:

\[ \frac{0,59\cdot 0,9}{0,59\cdot 0,9 + 0,41\cdot 0,1} = 0,93 \]

Durch die kombinierte Anwendung beider Tests ist die Erkrankung nun also
mit ca. 93\%-iger Sicherheit festgestellt. 
\marginline{Statistische Unabhängigkeit bei Testserien}
Eine wichtige Voraussetzung für die
verkettete Anwendung des Bayes'schen Lehrsatzes besteht darin, dass die
einzelnen Testverfahren statistisch voneinander unabhängig sind, d.h. wenn die
Testperson krank ist, darf die Wahrscheinlichkeit, dass der der zweite Test die
Krankheit korrekt diagnostiziert (positiv-positiv Rate) nicht davon abhängen, ob
auch der erste Test unter dieser Bedingung die Krankheit richtig diagnostiziert hat. 
Dasselbe gilt selbstverständlich auch für die positiv-negativ Rate. Wäre der
zweite Test in unserem Beispiel wiederum ein Gedächnistest gewesen, so hätte man
Anlass zu der Annahme, dass die beiden Tests nicht statistisch unabhängig voneinander
sind. (Für den Rechentest wollen wir einmal gutgläubig vermuten, dass er
statistisch unabhängig vom Gedächnistest ist.)

\subsubsection{Ein weiteres Anwendungsbeispiel: Wieviel Geld sind Informationen
wert?}
\label{WertVonInformtationen}
Der Bayes'sche Lehrsatz lässt sich auch einsetzen, wenn es darum geht, den
Wert von unsicheren Informationen zu beurteilen. Dazu muss man allerdings
zunächst klären, wie hoch man den Wert von Informationen überhaupt zu
veranschlagen hat. Resnik führt dazu folgendes gedachte Beispiel an
\cite[S. 57]{resnik:1987}:

Jemand steht vor der Entscheidung, € 50.000 in eine Firma zu investieren oder
lieber in Sparbriefen anzulegen. Die Investition in die Firma würde im Laufe
eines Jahres 5\% Zinsen einbringen, die in Sparbriefe 10\%. Was die Investition
in die Firma dennoch interessant macht ist, dass sie möglicherweise noch im
Laufe desselben Jahres an die Börse geht. Dann nämlich würden sich die
investierten € 50.000 verdoppeln. Als Entscheidungstabelle dargestellt, sieht
die Situation also folgendermaßen aus:

\begin{center}
\begin{tabular}{l|c|c|}
\multicolumn{1}{c}{} & \multicolumn{1}{c}{Börsengang} & \multicolumn{1}{c}{Kein
Börsengang} \\
\cline{2-3}
Investiere           & € 100.000                      & € 52.500 \\
\cline{2-3}
Kaufe Sparbriefe     & € 55.000                       & € 55.000 \\
\cline{2-3}
\end{tabular}
\end{center}

Angenommen, die Person, die vor dieser Entscheidung steht, hält sich an das
Indifferenzprinzip und geht davon aus, dass eine 50\% Chance besteht, dass die
Firma an die Börse geht. In diesem Fall hätte die Entscheidung zu investieren
einen Erwartungswert von € 100.000$\cdot 0.5$ + € 52.500$\cdot 0.5$ = € 76.250
und wäre damit dem Kauf von Sparbriefen vorzuziehen. Nun nehmen wir weiterhin an,
es gäbe in der Firma einen Insider, der mit Sicherheit sagen könnte, ob die Firma
im Laufe des Jahres an die Börse geht oder nicht, und dieser Insider wäre bereit,
seine Information zu verkaufen.\footnote{Aus gutem Grund verbieten die Gesetze
der meisten Länder übrigens sehr strikt den Gebrauch von Insiderwissen bei
Börsengeschäften, wie er in diesem Beispiel angenommen wird.} Wieviel Geld sollte
einem diese Information Wert sein. Das hängt wiederum davon ab, welche subjektive
Einschätzung man über die Wahrscheinlichkeit hat, dass die Information
dahingehend lautet, dass die Firma an die Börse geht. Nehmen wir an, dass in
Ermangelung näheren Wissens wiederum von einer 50\% Chance ausgegangen wird.
Welchen Erwartungswert erzielt man mit dieser Information? In diesem Fall lautet
die Rechnung € 100.000$\cdot 0.5$ + € 55.500$\cdot 0.5$ = € 77.500, weil in dem
Fall, dass man erfährt, dass die Firma doch nicht an die Börse geht, Sparbriefe
kaufen wird. Die Information sollte einem also höchstens € 1.250 Wert sein.

Um nun die Bayes'sche Formel ins Spiel zu bringen, gehen wir von der etwas
realistischeren Annahme aus, dass die Information des Insiders nicht völlig
zuverlässig ist. Wir nehmen vielmehr an, dass sie einem internen Bericht
entnommen ist, von dem nicht sicher ist, wie zuverlässig er ist. Angenommen
aus vergleichbaren Fällen ist bekannt, dass wenn ein Börsengang geplant ist,
dies mit einer 90\%-igen Wahrscheinlichkeit in dem Bericht korrekt mitgeteilt
wird, mit einer 10\%-igen Wahrscheinlichkeit aber das Gegenteil behauptet wird.
Angenommen weiterhin, wir hätten Grund zu der Annahme, dass wenn kein
Börsengang stattfinden wird, dennoch mit einer 50\%-igen Wahrscheinlichkeit in
dem Bericht behauptet wird, es würde ein Börsengang statt finden. 
Welche Überlegung muss die Person, die vor der Frage steht, ob es sich lohnt,
Geld in die Bestechung eines Informanden zu investieren, nun anstellen?
Zunächst müsste sie die Wahrscheinlichkeiten berechnen, mit der die Firma an
die Börse geht, falls dies in dem Bericht behauptet wird. Und ebenso müsste die
Wahrscheinlichkeit berechnet werden, falls dies in dem Bericht bestritten wird.

Für beide Rechnungen muss man die Bayes'sche Formel heranziehen. In beiden Fällen
ist die Basisrate wiederum die subjektive Wahrscheinlichkeit, die für einen
Börsengang spricht, und die wir nach dem Indifferenzprinzip auf 50\% festgesetzt
haben. Im ersten Fall beträgt die positiv-positiv-Rate 90\% und die
positiv-negativ-Rate 50\%. Wenn $b$ das Ereignis ist, dass die Firma an die
Börse geht und $j$ das Ereignis, dass im Bericht behauptet wird, dass sie es
tut, und $n$ das Ereignis, dass im Bericht behauptet wird, dass sie es nicht tut, dann
ergibt sich folgende Rechnung: \[ P(b|j) = \frac{P(b)P(j|b)}{P(b)P(j|b) + P(\neg
b)P(j|\neg b)} =
   \frac{0,5\cdot 0,9}{0,5\cdot 0,9 + 0,5\cdot 0,5} = 0,643 \]
Die Wahrscheinlichkeit, dass die Firma nicht an die Börse geht, wenn im Bericht
behauptet wird, dass sie es tut $P(\neg b|j)$, ist natürlich genau die inverse
Wahrscheinlichkeit, also $P(\neg b|j) = 1 - P(b|j) = 0,357$.

Im zweiten Fall, d.h. in dem Fall, dass der Bericht einen Börsengang dementiert,
betragen die entsprechenden Raten 10\% und 50\%. Die Rechnung sieht wie folgt
aus:
\[ P(b|n) = \frac{P(b)P(n|b)}{P(b)P(n|b) + P(\neg b)P(n|\neg b)} =
   \frac{0,5\cdot 0,1}{0,5\cdot 0,1 + 0,5\cdot0,5} = 0,167 \]
Die entsprechende inverse Wahrscheinlichkeit $P(\neg b|n)$ beträgt 0,833.

Für die Beantwortung der Frage, welchen Wert eine solche nur relativ zuverlässige
Information hat, müssen nun die Erwartungswerte berechnet werden, 1) für den
Fall, dass die Information dahingehend lautet, dass das Unternehmen an die Börse
geht, und 2) für den Fall, dass die Information anders lautet, wobei der durch
die eben berechneten Wahrscheinlichkeiten umschriebene Zuverlässigkeitsgrad der
Information zu berücksichtigen ist. Es ergibt sich in dem ersten Fall (Börsengang
wird behauptet) ein Erwartungswert von: \[ 0,643\cdot \mbox{€ 100.000} +
0,357\cdot \mbox{€ 52.500} = \mbox{€ 83.035,71} \] Und für den zweiten Fall: \[
0,167\cdot \mbox{€ 100.000} + 0,833\cdot \mbox{€ 52.500} = \mbox{€ 60.416,67} \]
Das bedeutet aber, dass egal wie die Information ausfällt, es auf jeden Fall
besser wäre, in die Firma zu investieren. Die Information selbst ist also
wertlos! Es gnügt das Wissen, dass es eine entsprechende Information überhaupt
gibt, und mit welchen Wahrscheinlichkeiten sie in dem ein oder anderen Fall
(Börsengang oder nicht) zurverlässig ist oder nicht, im Zusammenhang mit der
subjektiven Annahme einer gleichen Wahrscheinlichkeit für das Eintreten des
Ereignisses und das Nicht-Eintreten des Ereignisses.

(Nun könnte man noch die Frage anschließen, wie der Fall zu beurteilen
wäre, wenn -- bei anderen Wahrscheinlichkeiten -- im zweiten Fall ein Wert
herausgekommen wäre, der niedriger wäre als € 55.000. Dann müsste man, wie zuvor,
den Erwartungswert, mit dem man in dem Fall rechnet, dass die Information positiv
ausfällt, zu den € 55.000 addieren, die man in dem Fall erhält, dass die
Information negativ ausfällt und man Sparbriefe kaufen wird. Beide Summanden
müssten mit den subjektiven Wahrscheinlichkeitseinschätzungen dafür, wie die
Information ausfällt, gewichtet werden (wofür wir eine gleichverteilte
Wahrscheinlichkeit von 50\% veranschlagt hatten). Das Ergebnis wäre mit dem
Erwartungswert ohne jede Information von € 76.250 zu vergleichen, und
entsprechend der Differenz der Wert der Information zu veranschlagen.)

Bei diesem Beispiel ist zu beachten, dass die mit Hilfe des Bayes'schen
Lehrsatzes berechneten bedingten Wahrscheinlichkeiten davon abhängen, welche
subjektive Wahrscheinlichkeitseinschätzung man bezüglich der in die Bayes'sche
Formel eingesetzten Basisrate vornimmt. Es handelt sich um (rationale)
subjektive Wahrscheinlichkeitseinschätzungen, nicht um "`objektiv berechnete
Wahrscheinlichkeiten"'.

Damit sind wir wieder bei dem Problem der Interpretation von
Wahrscheinlichkeitsaussagen, d.h. bei Frage, ob es sich um Aussagen über
Häufigkeiten, subjektive Einschätzungen oder objektive "`Propensitäten"'
handelt. Mit diesem Problem werden wir uns in der nächsten Woche beschäftigen.


